{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dccc5ef",
   "metadata": {},
   "source": [
    "Dependency installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers google-generativeai pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036dcb5e",
   "metadata": {},
   "source": [
    "Read bembedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5debc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "E = np.load(\"embeddings.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4382f3",
   "metadata": {},
   "source": [
    "using sentence_transformaers to make query embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525460fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "st_model = SentenceTransformer(model_name, device=\"cpu\")\n",
    "\n",
    "def embed_query(text: str) -> np.ndarray:\n",
    "    return st_model.encode(\n",
    "        [text],\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "    )[0]  # (d,)\n",
    "\n",
    "def search(query: str, top_k: int = 5):\n",
    "    q = embed_query(query)           \n",
    "    scores = E @ q                   \n",
    "    idxs = np.argsort(-scores)[:top_k]\n",
    "\n",
    "    results = []\n",
    "    for i in idxs:\n",
    "        results.append({\n",
    "            \"score\": float(scores[i]),\n",
    "            \"idx\": int(i),\n",
    "            \"complaint_id\": df.loc[i, \"complaint_id\"] if \"complaint_id\" in df.columns else None,\n",
    "            \"text\": df.loc[i, \"text\"],\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd86477",
   "metadata": {},
   "source": [
    "Taking gemini key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3330542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY_HERE\"\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "\n",
    "def call_gemini(prompt: str) -> str:\n",
    "    model = genai.GenerativeModel(GEMINI_MODEL)\n",
    "    resp = model.generate_content(prompt)\n",
    "    try:\n",
    "        return resp.text\n",
    "    except Exception:\n",
    "        return str(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dea6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context(retrieved):\n",
    "    parts = []\n",
    "    for i, r in enumerate(retrieved):\n",
    "        head = f\"[Doc {i+1} | score={r['score']:.3f} | id={r['complaint_id']}]\"\n",
    "        parts.append(head + \"\\n\" + r[\"text\"])\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "def rag_answer(query: str, top_k: int = 5):\n",
    "    retrieved = search(query, top_k)\n",
    "    context = build_context(retrieved)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "User message:\n",
    "\\\"\\\"\\\"{query}\\\"\\\"\\\"\n",
    "\n",
    "Here are similar past consumer complaints:\n",
    "{context}\n",
    "\n",
    "Tasks:\n",
    "1. Classify the message as SCAM / NOT_SCAM / UNCERTAIN.\n",
    "2. Give a 2-4 sentence explanation.\n",
    "3. Reference helpful docs using \"Doc 2\", etc.\n",
    "Do NOT hallucinate facts not supported by the text.\n",
    "\"\"\"\n",
    "\n",
    "    answer = call_gemini(prompt)\n",
    "    return answer, retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b77c9f",
   "metadata": {},
   "source": [
    "Put query here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"A recruiter sent me a check and asked me to buy equipment and send back leftover money.\"\n",
    "\n",
    "answer, retrieved_docs = rag_answer(query, top_k=5)\n",
    "\n",
    "print(\"=== Gemini RAG Answer ===\\n\")\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n=== Retrieved Docs ===\\n\")\n",
    "for i, r in enumerate(retrieved_docs, start=1):\n",
    "    print(f\"[Doc {i} | score={r['score']:.3f} | id={r['complaint_id']}]\")\n",
    "    print(r[\"text\"][:350].replace(\"\\n\", \" \"), \"...\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
